{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "golden_run_path = \"cg/cg_in8/golden.log\"\n",
    "golden_run = pd.read_csv(golden_run_path,  sep=',', names=['file', 'linenum', 'variable', 'value'], header=0)\n",
    "golden_run_value = np.array(golden_run.value, dtype='float')\n",
    "cg_fault_injection = pd.read_csv('cg_in8.csv')\n",
    "SIZE = len(cg_fault_injection)\n",
    "print(SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg_fault_injection.outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 -- CG\n",
    "Take all the fault injections in the inital condition. Find all the fault injection cases that result into masked. For each masked case, compare error run with the golden run to get a error run curve. Combine all the error run curve to construct a error boundary for masked and SDC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg_fault_injection_experiment = pd.read_csv('matrix/in10_data/in10/injectlog.log',  sep=' ', names=['file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC Ratio over entire program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iters = list(cg_fault_injection.iter)\n",
    "iters.reverse()\n",
    "count  = 0\n",
    "last_zero_iteration_index = SIZE - iters.index(0)\n",
    "dynamic_step_to_record_computation_result = int(last_zero_iteration_index/64)\n",
    "\n",
    "for i in range(last_zero_iteration_index, len(iters)):\n",
    "    if cg_fault_injection.outcome[i] == \"SDC\":\n",
    "        count += 1\n",
    "\n",
    "print(\"SDC ratio over entire program: \", count/len(iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only tracking the maximum value of the masked run after this time step.\n",
    "tracking_length = len(golden_run_value)\n",
    "\n",
    "def construct_boundary(number_of_dynamic_instruction):\n",
    "    boundary = []\n",
    "    ground_truth = {\"Masked\": 0, \"SDC\":0, \"DUE\":0}\n",
    "\n",
    "    for i in range(tracking_length):\n",
    "        boundary.append({'max':0, 'min':0})\n",
    "\n",
    "    for i in range(number_of_dynamic_instruction):\n",
    "        index = int(random.random() * SIZE)\n",
    "        \n",
    "        ground_truth[cg_fault_injection.outcome[index]] += 1\n",
    "        \n",
    "        if cg_fault_injection.outcome[index] == \"Masked\":\n",
    "            masked_run_path = \"cg_simulation/appstate_\"+ str(index)+\".log\" \n",
    "\n",
    "            #Check whether the tracking file is on the path\n",
    "            #TODO: check whether can regenerate the data\n",
    "            if not os.path.isfile(masked_run_path):\n",
    "                continue\n",
    "\n",
    "            masked_run = pd.read_csv(masked_run_path,  sep=\",\", names=['file', 'linenum', 'variable', 'value'], header=0)\n",
    "            masked_run_value = np.array(masked_run.value, dtype='float')\n",
    "            \n",
    "            #This is a werid information in the data.\n",
    "            #TODO: may check why such outcome is shown\n",
    "            if len(masked_run_value) < tracking_length:\n",
    "                print(\"odd!\")\n",
    "                continue\n",
    "            \n",
    "            #array contain NAN, ignore the run\n",
    "            if np.isnan(np.min(masked_run_value)):\n",
    "                continue\n",
    "            \n",
    "            comparision_result = masked_run_value[0:tracking_length] - golden_run_value\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        for j in range(dynamic_step_to_record_computation_result, tracking_length):\n",
    "            if comparision_result[j] > boundary[j]['max'] and comparision_result[j] >= 0:\n",
    "                boundary[j]['max'] = comparision_result[j]\n",
    "\n",
    "            if comparision_result[j] < boundary[j]['min'] and comparision_result[j] < 0:\n",
    "                boundary[j]['min'] = comparision_result[j]\n",
    "                \n",
    "    return [boundary, ground_truth]\n",
    "\n",
    "def predict(boundary):\n",
    "    masked_true_positive = 0\n",
    "    masked_false_positive = 0\n",
    "    sdc_true_positive = 0\n",
    "    sdc_false_positive = 0\n",
    "    result = {}\n",
    "\n",
    "    for i in range(last_zero_iteration_index + 1, SIZE):\n",
    "        index = math.floor(i/64)\n",
    "        if cg_fault_injection.out_xor[i] < boundary[index]['max'] and cg_fault_injection.out_xor[i] > boundary[index]['min']:\n",
    "            if cg_fault_injection.outcome[i] == \"Masked\":\n",
    "                masked_true_positive += 1\n",
    "            else:\n",
    "                masked_false_positive += 1\n",
    "        else:\n",
    "            if cg_fault_injection.outcome[i] == \"SDC\":\n",
    "                sdc_true_positive += 1\n",
    "            else:\n",
    "                sdc_false_positive += 1\n",
    "\n",
    "    result[\"predict masked case\"] =  (masked_true_positive + masked_false_positive)/SIZE\n",
    "    result[\"predict SDC case\"] = (sdc_true_positive + sdc_false_positive)/SIZE\n",
    "    result[\"masked prediction accuracy\"] = masked_true_positive/(masked_true_positive + masked_false_positive)\n",
    "    result[\"SDC prediction accuracy\"] = sdc_true_positive/(sdc_true_positive + sdc_false_positive)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we think this as a lable propagation problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\n",
    "ground_truth = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    boundary = construct_boundary(2000)\n",
    "    \n",
    "    experiments.append(predict(boundary[0]))\n",
    "    ground_truth.append(boundary[1])\n",
    "\n",
    "    \n",
    "    \n",
    "uniform_test = []\n",
    "intuition = []\n",
    "\n",
    "for i in range(10):\n",
    "    intuition.append(experiments[i]['predict SDC case'])\n",
    "    uniform_test.append(ground_truth[i]['SDC']/2000)\n",
    "\n",
    "print(np.mean(intuition))\n",
    "print(intuition)\n",
    "print(np.mean(uniform_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Experiment 2 -- FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"fft/fft_complete/\"\n",
    "\n",
    "golden_run_path = path+\"golden.log\"\n",
    "golden_run = pd.read_csv(golden_run_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "golden_run_value = np.array(golden_run.value, dtype='float')\n",
    "fault_injection_experiment = pd.read_csv(path+'injectlog.log',  sep=' ', names=['file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])\n",
    "SIZE = len(fault_injection_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    golden_run_path = path + \"golden.log\"\n",
    "    golden_run = pd.read_csv(golden_run_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "    golden_run_value = np.array(golden_run.value, dtype='float')\n",
    "    fault_injection_experiment = pd.read_csv(path+\"injectlog.log\",  sep=' ', names=['file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])\n",
    "    \n",
    "    return [golden_run,fault_injection_experiment]\n",
    "\n",
    "def SDC_ratio(experiments): \n",
    "    sdc_count = 0\n",
    "    for i in range(len(experiments)):\n",
    "        if float(np.array(experiments.diffnorm)[i]) > 0.07:\n",
    "            sdc_count += 1\n",
    "    \n",
    "    return sdc_count / len(experiments)\n",
    "\n",
    "def getBoundary(golden_run, percent, experiments, path):\n",
    "    boundary = []\n",
    "    nums = int(len(experiments) * percent)\n",
    "\n",
    "    for i in range(len(golden_run)):\n",
    "        boundary.append({\"min\": 0, \"max\":0})\n",
    "\n",
    "    for i in range(nums):\n",
    "        if float(np.array(experiments.diffnorm)[i]) > 0.07:\n",
    "            continue\n",
    "    \n",
    "        index = int(random.random() * len(experiments))\n",
    "\n",
    "        file_path = path+\"appstate_\"+str(index)+\".log\"\n",
    "    \n",
    "        fault_inject_run = pd.read_csv(file_path,  sep=' ', names=[\"file\", \"linenum\", \"variable\", \"value\"])\n",
    "    \n",
    "        if len(fault_inject_run) < len(golden_run):\n",
    "            print(\"weird!\")\n",
    "            continue\n",
    "    \n",
    "        values = np.array(fault_inject_run.value[0:len(golden_run)], dtype=\"float\") - np.array(golden_run.value, dtype=\"float\")\n",
    "    \n",
    "        for j in range(len(golden_run)):\n",
    "            if values[j] >= 0 and values[j] > boundary[j][\"max\"]:\n",
    "                boundary[j][\"max\"] = values[j]\n",
    "                       \n",
    "            if values[j] < 0 and values[j] < boundary[j][\"min\"]:\n",
    "                boundary[j][\"min\"] = values[j] \n",
    "    \n",
    "    return boundary\n",
    "\n",
    "def prediction(experiments, boundary):\n",
    "    positive_prediction = 0\n",
    "    negative_prediction = 0\n",
    "    \n",
    "    start_index = int(len(experiments.diffnorm)*0.4)\n",
    "    end_index = len(experiments.diffnorm)\n",
    "    \n",
    "    for i in range(start_index, end_index):\n",
    "        index = math.floor(i/64)\n",
    "        inject_error = float(np.array(experiments.corrupt_value)[i]) - float(np.array(experiments.init_value)[i])\n",
    "    \n",
    "        if(inject_error > boundary[index][\"min\"] and inject_error < boundary[index][\"max\"]):\n",
    "            if float(np.array(experiments.diffnorm)[i]) < 0.07:\n",
    "                positive_prediction += 1\n",
    "            else:\n",
    "                negative_prediction += 1\n",
    "    \n",
    "    return {\"positive\": positive_prediction/len(experiments), \"negative\": negative_prediction/len(experiments)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Result of 20 x 20 Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhimin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2163264\n"
     ]
    }
   ],
   "source": [
    "golden_run, experiments = load_data(path)\n",
    "boundary = getBoundary(golden_run, 0.01, experiments, path)\n",
    "experiments = pd.read_csv(\"fft/fft_injectlog.log\",  sep=' ', names=['file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])\n",
    "\n",
    "print(len(experiments))\n",
    "print(SDC_ratio(experiments))\n",
    "#print(prediction(experiments, boundary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SDC_ratio(experiments))\n",
    "#np.array(experiments.diffnorm)[641:700]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(SDC_ratio(experiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using 6400 fault injections run in FFT to test the masked case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary = []\n",
    "\n",
    "for i in range(len(golden_run)):\n",
    "    boundary.append({\"min\": 0, \"max\":0})\n",
    "\n",
    "for i in range(8400):\n",
    "    \n",
    "    if fault_injection_experiment.diffnorm[i] > 0.07:\n",
    "        continue\n",
    "    \n",
    "    index = int(random.random() * len(fault_injection_experiment))\n",
    "\n",
    "    file_path = \"matrix/in27_data/in27/appstate_\"+str(index)+\".log\"\n",
    "    \n",
    "    fault_inject_run = pd.read_csv(file_path,  sep=' ', names=[\"file\", \"linenum\", \"variable\", \"value\"])\n",
    "    \n",
    "    if len(fault_inject_run) < len(golden_run):\n",
    "        print(\"weird!\")\n",
    "        continue\n",
    "    \n",
    "    values = np.array(fault_inject_run.value[0:len(golden_run)], dtype=\"float\") - np.array(golden_run.value, dtype=\"float\")\n",
    "    \n",
    "    for j in range(len(golden_run)):\n",
    "        if values[j] >= 0 and values[j] > boundary[j][\"max\"]:\n",
    "            boundary[j][\"max\"] = values[j]\n",
    "                       \n",
    "        if values[j] < 0 and values[j] < boundary[j][\"min\"]:\n",
    "            boundary[j][\"min\"] = values[j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_prediction = 0\n",
    "negative_prediction = 0\n",
    "for i in range(len(fault_injection_experiment.diffnorm)):\n",
    "    \n",
    "    index = math.floor(i/64)\n",
    "    \n",
    "    #if i%64 <= 52:\n",
    "    #    continue\n",
    "    \n",
    "    inject_error = float(fault_injection_experiment.corrupt_value[i]) - float(fault_injection_experiment.init_value[i])\n",
    "    \n",
    "    if(inject_error > boundary[index][\"min\"] and inject_error < boundary[index][\"max\"]):\n",
    "        if fault_injection_experiment.diffnorm[i] < 0.07:\n",
    "            positive_prediction += 1\n",
    "        else:\n",
    "            negative_prediction += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#relative error and absolute error\n",
    "#for i in range(len(golden_run_value)):\n",
    "#   if golden_run_value[i] != 0:\n",
    "#        absolute = abs(golden_run_value[i] -  masked_run_value[i])\n",
    "\n",
    "false_positive = 0\n",
    "true_positive = 0\n",
    "unsure = 0\n",
    "total = (811 - 160) * 64\n",
    "for i in range(160, 811):\n",
    "    diff = abs(golden_run_value[i] -  masked_run_value[i]) \n",
    "    for b in range(64):\n",
    "        if diff > abs(cg_fault_injection.out_xor[i * 64 + b]) and cg_fault_injection.outcome[i * 64 + b] != \"Masked\":\n",
    "            #print(cg_fault_injection.diffnormr[i * 64 + b], cg_fault_injection.Variable[i * 64 + b], (diff - abs(cg_fault_injection.out_xor[i * 64 + b])))\n",
    "            false_positive += 1\n",
    "            print(i * 64 + b)\n",
    "        elif diff > abs(cg_fault_injection.out_xor[i * 64 + b]) and cg_fault_injection.outcome[i * 64 + b] == \"Masked\":\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            unsure += 1\n",
    "    \n",
    "    #sdc_diff = abs(golden_run_value[i] -  sdc_run_value[i])\n",
    "    #for b in range(64):\n",
    "    #    if sdc_diff < abs(cg_fault_injection.out_xor[i * 64 + b]) and cg_fault_injection.outcome[i * 64 + b] != \"SDC\":\n",
    "    #        false_positive += 1\n",
    "    #    elif sdc_diff < abs(cg_fault_injection.out_xor[i * 64 + b]) and cg_fault_injection.outcome[i * 64 + b] == \"SDC\":\n",
    "    #        true_positive += 1\n",
    "    #    else:\n",
    "    #        unsure +=1\n",
    "            \n",
    "print(false_positive/total)\n",
    "print(true_positive/total)\n",
    "print(unsure/total)\n",
    "    \n",
    "#print(i, cg_fault_injection.Variable[i], cg_fault_injection.out_xor[i], cg_fault_injection.outcome[i])\n",
    "#for i in range(243*64,244*64):\n",
    "#    print(i,cg_fault_injection.Variable[i], cg_fault_injection.out_xor[i], cg_fault_injection.outcome[i])\n",
    "#print(golden_run_value[243])\n",
    "#print(len(cg_fault_injection))\n",
    "#golden_run_value-error_run_value[0:811]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_instructions = {}\n",
    "\n",
    "propagation_path = []\n",
    "\n",
    "for index in range(100):\n",
    "    if index in[15731, 16246, 17523]:\n",
    "        continue\n",
    "    \n",
    "    file_path = \"cg_simulation/appstate_\"+str(index)+\".log\"\n",
    "    error_run = pd.read_csv(file_path,  sep=' ')\n",
    "    \n",
    "    \n",
    "    #For different fault injection case, what is the number of different execution dynamic instructions\n",
    "    if len(error_run) in number_of_instructions:\n",
    "        number_of_instructions[len(error_run)] += 1\n",
    "    else:\n",
    "        number_of_instructions[len(error_run)] = 1\n",
    "        \n",
    "    #\n",
    "    index = min(len(golden_run), len(error_run))\n",
    "    #result = np.array(golden_run.value, dtype=float)[:index] - np.array(error_run.value, dtype=float)[:index]\n",
    "    #propagation_elements = golden_run.line[np.where(result != 0)[0]]\n",
    "    \n",
    "    #path = \"=>\"\n",
    "    #number_of_propagation_element = 5\n",
    "    #for e in propagation_elements:\n",
    "    #    if str(e) not in path:\n",
    "    #        path += str(e)\n",
    "    #        path += \"=>\"\n",
    "    #        number_of_propagation_element -= 1\n",
    "        \n",
    "    #    if number_of_propagation_element == 0:\n",
    "    #        break\n",
    "    #if path not in propagation_path:\n",
    "    #    propagation_path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the probability of the different number of storing dynamic instructions.\n",
    "## What is the probability of SDC.\n",
    "\n",
    "It's expected that if the program ends early, then there an unexpected crash during the program execution in the earlier stage. At the same time, if the program has more execution than it expected. It will have high chance causes silent data corruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg_outcome = cg_fault_injection['outcome'].value_counts()\n",
    "\n",
    "print(cg_outcome)\n",
    "print(sum(cg_outcome))\n",
    "#propagation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# If you want to rewrite your code.\n",
    "\n",
    "4. interactive fault injection campaign.\n",
    "\n",
    "### 1. A sensitive analysis across the whole program with a mapping framework.\n",
    "A desity scatter plot to understand the input and output sensitivity of the program. User can selective choose the high sensitive data and mapping back to the original visualization.\n",
    "    \n",
    "    a. how many clusters in the plot.\n",
    "    \n",
    "    b. Where is each of them comes from. \n",
    "    \n",
    "    c. The sample that comes from the fault injection in same location.\n",
    "\n",
    "#### 2. Explore function level resiliency of the program. What's the difference compare to the source code level?\n",
    "\n",
    "    a.Explore the resiliency of different program component. Aggregate the data in variable level\n",
    "\n",
    "\n",
    "#### 3. How to measure the impact of one variable/function over the other?\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The number of times a function is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = {}\n",
    "\n",
    "line_to_func = {167:'readA', 175:'readB', 33:'waxpby', 25:'matvec', 48:'dot_r2', 75:'solve_cg', 76:'solve_cg',87:'solve_cg',57:'dot', 90:'solve_cg',91:'solve_cg',40:\"daxpby\", 82:'daxpby',83:'daxpby',84:'daxpby'}\n",
    "\n",
    "for index, row in golden_run.iterrows():\n",
    "    key = line_to_func[row['line']]\n",
    "    if key not in counter:\n",
    "        counter[key] = 1\n",
    "    else:\n",
    "        counter[key] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_instruction = sum(list(counter.values()))\n",
    "for item in counter.items():\n",
    "    print(item[0], item[1]/number_of_instruction * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Error Propagation Analysis in one program component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "golden_run_path = \"cg_simulation/golden.log\"\n",
    "golden_run = pd.read_csv(golden_run_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "golden_run_value = np.array(golden_run.value)\n",
    "##### this is a very interesting but werid case\n",
    "##### There is a NAN occur during the computation, but the  error is masked at the end.\n",
    "#index_range = [17341, 24381]\n",
    "\n",
    "##### cg p_ap_dot first interation 64 experiment\n",
    "#index_range = [15552, 15603]\n",
    "\n",
    "#file_path = \"cg_simulation1/appstate_\"+str(17341)+\".log\"\n",
    "#error_run = pd.read_csv(file_path,  sep=' ')\n",
    "\n",
    "#for i in range(len(error_run.value)):\n",
    "#    print(error_run.line[i], error_run.variable[i], error_run.value[i])\n",
    "#print(len(error_run.value))\n",
    "\n",
    "#print(error_run)\n",
    "#data_set = {}\n",
    "\n",
    "\n",
    "#golden_run_value = np.array(golden_run.value[0:800], dtype='float')\n",
    "\n",
    "#for index in range(index_range[0], index_range[1]+1):\n",
    "#    file_path = \"cg_simulation/appstate_\"+str(index)+\".log\"\n",
    "#    error_run = pd.read_csv(file_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "\n",
    "#    data_set[index] = golden_run_value - np.array(error_run.value[0:800], dtype='float')\n",
    "\n",
    "\n",
    "##### a specific case line 75 case 10290\n",
    "##### a specific case line 75 case 10296\n",
    "indexs =  [10290, 10274]# 10288] #10297]# 10296, 10289]\n",
    "\n",
    "delta_x = [65536, 1.0]# 1321922331132047.5]#, -307779.3308780107]\n",
    "x_data = range(0, 811, 1)\n",
    "\n",
    "for index,item in enumerate(indexs): \n",
    "    file_path = \"cg_simulation/appstate_\"+str(item)+\".log\"\n",
    "    error_run = pd.read_csv(file_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "    error_run_value = np.array(error_run.value)\n",
    "\n",
    "    sensitivity_val = (error_run_value[0:811] - golden_run_value[0:811])/delta_x[index]\n",
    "    sns.lineplot(x=x_data, y=sensitivity_val, sort=False, lw=1)\n",
    "    \n",
    "print(sensitivity_val.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for index in range(index_range[0], index_range[1]+1):\n",
    "#    print(len(data_set[index].values))\n",
    "#data_set[index] = golden_run.values - error_run.values   \n",
    "\n",
    "\n",
    "x_data = range(0,811,1)\n",
    "sns.lineplot(x=x_data, y=sensitivity_val, sort=False, lw=1)\n",
    "\n",
    "#for index in range(index_range[0], index_range[0]+20): \n",
    "#    sns.lineplot(x=x_data, y=data_set[index], sort=False, lw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What role the truncation error is playing in the propagation analysis\n",
    "## What's the threshold of different program components.\n",
    "## How much error is masked by the truncate error and How much error is masked by the model feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
