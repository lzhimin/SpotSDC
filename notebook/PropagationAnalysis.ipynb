{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem need to be addressed \n",
    "\n",
    "In this research, we proposal a new fault tolerance analysis technique - fault tolerance boundary is designed specific to the data variable.\n",
    "1. What's the fault tolerance boundary.\n",
    "2. It's a technique can be equivlent to the fault injection campaign.\n",
    "3. We propose a method to approximate the boundary.\n",
    "    1. heuristic method to measure the boundary.\n",
    "    2. correlation analysis between variables to understand the relationship between the fault tolerance across variables.\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from IPython.core.debugger import set_trace\n",
    "from datetime import datetime\n",
    "import sys\n",
    "random.seed(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET = \"bs\" #current available datasets fft, lu, cg, other potential dataset.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SDC ratio in this experiment is 0.6884949882075472\n",
      "The size of the experiment is 27136\n",
      "The size of the exhaust fault injection experiments 2713600\n"
     ]
    }
   ],
   "source": [
    "# Threshold that used to decide whether the final outcome is SDC or Masked. For the loading data\n",
    "# set, there are two different datasets. One is the exhaust fault injection campaign which contains\n",
    "# all the fault injection information. The other is the test data set which is the sample experiment \n",
    "# contain the detail propagation information used for the downstream propagation analysis.\n",
    "PROPAGATION_DATA_PATH = \"\"\n",
    "CAMPAIGN_DATA_PATH = \"\"\n",
    "PROPAGATION_INJECTION_DATA_PATH = \"\"\n",
    "THRESHOLD = 0\n",
    "\n",
    "if DATASET == \"fft\":\n",
    "    PROPAGATION_DATA_PATH = \"../static/data/fft/fft_complete\"\n",
    "    CAMPAIGN_DATA_PATH = \"../static/data/fft/fft_injectlog.log\"\n",
    "    #PROPAGATION_INJECTION_DATA_PATH = \"../static/data/fft_complete.csv\"\n",
    "    THRESHOLD = 0.001\n",
    "elif DATASET == \"cg\":\n",
    "    PROPAGATION_DATA_PATH = \"../static/data/cg/cg_in8\"\n",
    "    CAMPAIGN_DATA_PATH = \"../static/data/cg/cg_in8/injectlog.log\"\n",
    "    #PROPAGATION_INJECTION_DATA_PATH = \"../static/data/cg_in8.csv\"\n",
    "    THRESHOLD = 0.07\n",
    "elif DATASET == \"lu\":\n",
    "    PROPAGATION_DATA_PATH = \"../static/data/lu/lu20000\"\n",
    "    CAMPAIGN_DATA_PATH = \"../static/data/lu/injectlog.log\"\n",
    "    #PROPAGATION_INJECTION_DATA_PATH = \"../static/data/lu_complete.csv\"\n",
    "    THRESHOLD = 0.0001\n",
    "elif DATASET == 'bs':\n",
    "    PROPAGATION_DATA_PATH = \"../static/data/black-scholes/\"\n",
    "    CAMPAIGN_DATA_PATH = \"../static/data/black-scholes/injectlog_complete.log\"\n",
    "    #PROPAGATION_INJECTION_DATA_PATH = \"\"\n",
    "    THRESHOLD = 0.0001\n",
    "     \n",
    "# The fault injection campaign experiment\n",
    "FAULT_INJECTION_CAMPAIGN = pd.read_csv(CAMPAIGN_DATA_PATH,  sep=\" \", names=['fileindex', 'file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])\n",
    "\n",
    "# The size of the fault injection experiment\n",
    "SIZE = len(FAULT_INJECTION_CAMPAIGN)\n",
    "\n",
    "# The percentage of the test experiment over exhaust fault injection campaign.\n",
    "TEST_EXPERIMENT_NUMBER = int(SIZE * 0.01)\n",
    "\n",
    "# Golden Run\n",
    "GOLDEN_RUN = pd.read_csv(PROPAGATION_DATA_PATH+\"/golden.log\",  sep=\" \", names=['file', 'linenum', 'variable', 'value'])\n",
    "\n",
    "# Subset of fault injection campaign that used to verify the quality of a dynamic instruction\n",
    "# FAULT_INJECTION_TEST_CAMPAIGN = pd.read_csv(TEST_PATH, sep=\",\")\n",
    "TEST_EXPERIMENTS = FAULT_INJECTION_CAMPAIGN.sample(n=TEST_EXPERIMENT_NUMBER, replace=False,  random_state=1)\n",
    "\n",
    "# SDC ratio of test experiments\n",
    "SDC_COUNT = 0\n",
    "for index, row in FAULT_INJECTION_CAMPAIGN.iterrows():\n",
    "    if float(row['diffnorm']) > THRESHOLD:\n",
    "        SDC_COUNT += 1\n",
    "\n",
    "print(\"The SDC ratio in this experiment is\",SDC_COUNT/len(FAULT_INJECTION_CAMPAIGN))\n",
    "print(\"The size of the experiment is\",  len(TEST_EXPERIMENTS))\n",
    "print(\"The size of the exhaust fault injection experiments\", len(FAULT_INJECTION_CAMPAIGN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golden Fault Injection Boundary\n",
    "Golden fault injection boundary use the exhaust fault inject campaign to build the boundary in practical sense. If the error value is above a specific threshold, then the location will not tolerance the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 802800, 'negative': 0, 'crash': 0, 'accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# In fault injection campaign analysis, the prediction outcome is positive and negative.\n",
    "# during the prediction process, we ignore the crash case.\n",
    "# For the prediction, we need to think about four different cases\n",
    "# True negative, False positive\n",
    "# False negative, True positive\n",
    "def predict(boundary):\n",
    "    positive_prediction = 0\n",
    "    crash = 0\n",
    "    negative_prediction = 0\n",
    "    result = {}\n",
    "    bits = []\n",
    "    nan = float('nan')\n",
    "    inf = float('inf')\n",
    "\n",
    "    for index, row in FAULT_INJECTION_CAMPAIGN.iterrows():\n",
    "        instruction_index = int(row[\"byte_num\"].split(\"#\")[1])\n",
    "        inject_error = 0\n",
    "        corrupt_value = float(row['corrupt_value'])\n",
    "        init_value = float(row['init_value'])\n",
    "        \n",
    "        if init_value != 0 and corrupt_value != nan and corrupt_value != inf:\n",
    "            inject_error = abs((corrupt_value - init_value)/init_value)\n",
    "        \n",
    "        diffnorm = float(row['diffnorm'])\n",
    "        if inject_error < boundary[instruction_index]:\n",
    "            #bits.append(row[\"bit\"])\n",
    "            if diffnorm < THRESHOLD:\n",
    "                positive_prediction += 1\n",
    "            elif math.isnan(diffnorm) or math.isinf(diffnorm):\n",
    "                crash += 1\n",
    "            else:\n",
    "                negative_prediction += 1     \n",
    "    \n",
    "    result[\"positive\"] = positive_prediction\n",
    "    result[\"negative\"] = negative_prediction\n",
    "    result[\"crash\"] = crash\n",
    "    result[\"accuracy\"] = positive_prediction/(positive_prediction + crash + negative_prediction)\n",
    "    \n",
    "    return (result, bits)\n",
    "\n",
    "def getGoldenFaultToleranceBoundary():\n",
    "    boundary = {}\n",
    "    nan = float('nan')\n",
    "    inf = float('inf')\n",
    "    for index, row in FAULT_INJECTION_CAMPAIGN.iterrows():\n",
    "        corrupt_value = float(row['corrupt_value'])\n",
    "        init_value = float(row['init_value'])\n",
    "        inject_error = 0\n",
    "        norm = float(row[\"diffnorm\"])\n",
    "        \n",
    "        try:\n",
    "            instruction_index = int(row[\"byte_num\"].split(\"#\")[1])\n",
    "        except:\n",
    "            print(row)\n",
    "        \n",
    "        if init_value != 0 and corrupt_value != nan and corrupt_value != inf:\n",
    "            inject_error = abs((corrupt_value - init_value)/init_value)\n",
    "  \n",
    "        if instruction_index not in boundary:\n",
    "            boundary[instruction_index] = float(\"+inf\")\n",
    "        \n",
    "        if norm > THRESHOLD:\n",
    "            if boundary[instruction_index] > inject_error:\n",
    "                boundary[instruction_index] = inject_error    \n",
    "    return boundary\n",
    "\n",
    "boundary = getGoldenFaultToleranceBoundary()\n",
    "print(predict(boundary)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Single Fault Injection Experiment\n",
    "\n",
    "Understand how a single fault injection experiment can help to understand the result of the other fault injection experiment.\n",
    "\n",
    "Randomly select 1000 fault injection experiments and test the prediction accuracy of each masked experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The number of fault injection experiments that a single fault injection can predict is masked.\n",
    "def single_masked_prediction(fault_inject_run, golden_run, experiments, threshold = 0.001):\n",
    "    \n",
    "    # The experiment ends early\n",
    "    if len(fault_inject_run) < len(golden_run):\n",
    "        print(\"Bad fault injection experiment!\")\n",
    "        return False\n",
    "    \n",
    "    # Get the prediction boundary of a single fault injection experiment.\n",
    "    boundary = np.abs(np.array(fault_inject_run.value[0:len(golden_run)], dtype=\"float\") - np.array(golden_run.value, dtype=\"float\"))    \n",
    "    if np.isnan(boundary).any() or np.isinf(boundary).any():\n",
    "        print(\"This experiment outcome is masked, but the propagation process contains nan or infinity event\")\n",
    "        return False\n",
    "    \n",
    "    # The number of tested experiment\n",
    "    # print(len(experiments))\n",
    "    \n",
    "    positive_prediction = 0\n",
    "    negative_prediction = 0\n",
    "    SDC_count = 0\n",
    "    crash = 0\n",
    "    count = len(experiments)\n",
    "  \n",
    "    for index, row in experiments.iterrows():\n",
    "        \n",
    "        #if pd.isna(row[\"byte_num\"]):\n",
    "        #    continue\n",
    "        \n",
    "        #print(row['byte_num'], np.isnan(row[\"byte_num\"]))\n",
    "        instruction_index = int(row[\"byte_num\"].split(\"#\")[1])\n",
    "        inject_error = abs(float(row[\"corrupt_value\"]) - float(row[\"init_value\"]))\n",
    "        diffnorm = float(row['diffnorm'])\n",
    "        \n",
    "        if inject_error <= boundary[instruction_index]:\n",
    "            if diffnorm < threshold:\n",
    "                positive_prediction += 1\n",
    "            elif math.isnan(diffnorm) or math.isinf(diffnorm):\n",
    "                crash += 1\n",
    "            else:\n",
    "                negative_prediction += 1     \n",
    "    \n",
    "    if (positive_prediction + negative_prediction) is 0:\n",
    "        return {\"crash\":crash/count, \"positive\": positive_prediction/count, \"negative\": negative_prediction/count, \"accuracy\":0,  \"total\":positive_prediction+negative_prediction}    \n",
    "    else:\n",
    "        return {\"crash\":crash/count, \"positive\": positive_prediction/count, \"negative\": negative_prediction/count, \"total\":positive_prediction+negative_prediction, \"accuracy\":positive_prediction/(positive_prediction + negative_prediction+crash)}  \n",
    "\n",
    "#The number of fault injection experiment that the program can predict as SDC\n",
    "def single_SDC_prediction(fault_inject_run, golden_run, experiments, threshold = 0.001):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# During the fault injection experiment, filter out the bad prediction case and left with the good prediction case.\n",
    "GOOD_MASKED_RUN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../static/data/black-scholes//appstate_2002402.log' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-05fa3157f590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#verify the select fault injection experiment is valuable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnorm\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mTHRESHOLD\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mfault_inject_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPROPAGATION_DATA_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/appstate_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".log\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'linenum'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'variable'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mpre_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msingle_masked_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfault_inject_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGOLDEN_RUN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFAULT_INJECTION_CAMPAIGN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTHRESHOLD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../static/data/black-scholes//appstate_2002402.log' does not exist"
     ]
    }
   ],
   "source": [
    "diffnorms = np.array(FAULT_INJECTION_CAMPAIGN.diffnorm, dtype='float')\n",
    "length = len(TEST_EXPERIMENTS)\n",
    "list_indexs = []\n",
    "pre_res = {}\n",
    "index = 0\n",
    "#Understand the pruning technique.\n",
    "for _, row in TEST_EXPERIMENTS.iterrows():\n",
    "    file_index = row[\"fileindex\"]\n",
    "    norm = float(row[\"diffnorm\"])\n",
    "    \n",
    "    index += 1\n",
    "    if index % (length/10) ==0:\n",
    "        print(index/float(length), \"experiment\")\n",
    "    \n",
    "    #verify the select fault injection experiment is valuable\n",
    "    if norm != 0 and not np.isinf(norm) and not math.isnan(norm) and norm < THRESHOLD :\n",
    "        fault_inject_run = pd.read_csv(PROPAGATION_DATA_PATH+\"/appstate_\"+str(file_index)+\".log\",  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "        pre_res = single_masked_prediction(fault_inject_run, GOLDEN_RUN, FAULT_INJECTION_CAMPAIGN, THRESHOLD)\n",
    "        \n",
    "        #if the predictor reject the current experiment for prediction, continue to next experiment\n",
    "        if not pre_res:\n",
    "            continue\n",
    "        \n",
    "        if pre_res['accuracy'] >= 1 :\n",
    "            GOOD_MASKED_RUN.append(file_index)\n",
    "        \n",
    "        list_indexs.append({\"diffnorm\":math.log10(norm), \"index\":index, \"crash\":pre_res[\"crash\"], \"negative\":pre_res[\"negative\"], \"positive\":pre_res[\"positive\"], 'accuracy':pre_res['accuracy']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure()\n",
    "list_indexs = sorted(list_indexs, key = lambda i: i['diffnorm']) \n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "k = []\n",
    "for i in range(len(list_indexs)):\n",
    "    x.append(list_indexs[i]['diffnorm'])\n",
    "    y.append(list_indexs[i]['positive'] + list_indexs[i]['negative'] + list_indexs[i]['crash'])\n",
    "    z.append(list_indexs[i]['negative'])\n",
    "    k.append(list_indexs[i]['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.axes_style('white')\n",
    "df = pd.DataFrame(data = {\"x\":x, \"y\":y, \"k\":k,\"z\":z})\n",
    "\n",
    "plt.scatter(x, y, c=k, cmap='viridis')\n",
    "plt.xlabel('norm(log10)')\n",
    "plt.ylabel('prediction rate')\n",
    "#plt.clim(0,1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(df.x)\n",
    "plt.xlabel('norm')\n",
    "plt.ylabel('number of experiments')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(df.y)\n",
    "plt.xlabel('positive prediction')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(df.k)\n",
    "plt.xlabel('prediction accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(df.z)\n",
    "plt.xlabel('negative prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We use a first 1000 experiment as a filter to filter out outlier propagation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracking_length = len(GOLDEN_RUN.value)\n",
    "def construct_boundary(cases):\n",
    "    boundary = []\n",
    "    for i in range(tracking_length):\n",
    "        boundary.append(0)\n",
    "\n",
    "    for i in range(len(cases)):\n",
    "        index = cases[i]\n",
    "        #masked_run_path = \"../static/data/cg/cg_in8/appstate_\"+ str(index)+\".log\" \n",
    "        masked_run_path = PATH +\"/appstate_\"+ str(index) + \".log\"\n",
    "        #Check whether the tracking file is on the path\n",
    "        #TODO: check whether can regenerate the data\n",
    "        #print(masked_run_path)\n",
    "        if not os.path.isfile(masked_run_path):\n",
    "            print(\"file does not exist\")\n",
    "            continue\n",
    "\n",
    "        masked_run = pd.read_csv(masked_run_path,  sep=\" \", names=['file', 'linenum', 'variable', 'value'])\n",
    "        masked_run_value = np.array(masked_run.value, dtype='float')\n",
    "        \n",
    "        #This is a werid information in the data.\n",
    "        #TODO: may check why such outcome is shown\n",
    "        if len(masked_run_value) < tracking_length:\n",
    "            print(\"odd!\")\n",
    "            continue\n",
    "\n",
    "        #array contain NAN, ignore the run\n",
    "        if np.isnan(np.min(masked_run_value)):\n",
    "            continue\n",
    "\n",
    "        comparision_result = np.abs(masked_run_value[0:tracking_length] - GOLDEN_RUN.value)\n",
    "        for j in range(tracking_length):\n",
    "            if comparision_result[j] > boundary[j]:\n",
    "                boundary[j] = comparision_result[j]\n",
    "                \n",
    "    return boundary\n",
    "\n",
    "def predict(boundary):\n",
    "    positive_prediction = 0\n",
    "    crash = 0\n",
    "    negative_prediction = 0\n",
    "    result = {}\n",
    "    bits = []\n",
    "\n",
    "    for index, row in FAULT_INJECTION_TEST_CAMPAIGN.iterrows():\n",
    "        instruction_index = int(row[\"DI\"]) \n",
    "        \n",
    "        inject_error = abs(row[\"out_xor\"])\n",
    "        diffnorm = float(row['diffnormr'])\n",
    "        \n",
    "        if inject_error <= boundary[instruction_index]:\n",
    "            bits.append(row[\"bit\"])\n",
    "            if diffnorm < THRESHOLD:\n",
    "                positive_prediction += 1\n",
    "            elif math.isnan(diffnorm) or math.isinf(diffnorm):\n",
    "                crash += 1\n",
    "            else:\n",
    "                negative_prediction += 1     \n",
    "    \n",
    "    result[\"positive\"] = positive_prediction\n",
    "    result[\"negative\"] = negative_prediction\n",
    "    result[\"crash\"] = crash\n",
    "    result[\"accuracy\"] = positive_prediction/(positive_prediction + crash + negative_prediction)\n",
    "    \n",
    "    return (result, bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(FAULT_INJECTION_TEST_CAMPAIGN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary = construct_boundary(GOOD_MASKED_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res, bits = predict(boundary)\n",
    "plt.hist(bits)\n",
    "print(res)\n",
    "#plt.hist(df.x)\n",
    "#plt.xlabel('norm')\n",
    "#plt.ylabel('number of experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the boundary\n",
    "plt.plot(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Golden Boundary of the Fault Injection Experiment\n",
    "\n",
    "1. A bit map base boundary\n",
    "2. A value scale base boundary\n",
    "\n",
    "In the following code, the construction of the golden boundary is based on the exhuast fault injection campaign.\n",
    "The method of using boundary analysis is based on the assumption that for each fault injection location, there is \n",
    "a threshold such that the inject error exceed that value will result into SDC outcome.\n",
    " \n",
    " \n",
    "Using the fault injection campaign to construct the boundary is also not perfect because each location has 64 sample to estimate the threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = \"fft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "# Threshold that used to decide whether the final outcome is SDC or Masked.\n",
    "threshold = 0.01\n",
    "\n",
    "if dataset == \"cg\":\n",
    "    path = \"../static/data/cg_in8.csv\"\n",
    "    threshold = 0.07\n",
    "elif dataset == \"fft\":\n",
    "    path = \"../static/data/fft_complete.csv\"\n",
    "    threshold = 0.001\n",
    "elif dataset == \"lu\":\n",
    "    path = \"../static/data/lu_complete.csv\"\n",
    "    threshold = 0.0001\n",
    "\n",
    "fault_injection_campaign = pd.read_csv(path)\n",
    "#fault_injection_campaign\n",
    "#File index, Function, Line, Variable, out_xor, out_xor_relative, diffnormr, outcome, iter, bit, DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masked_golden_boundary = {}\n",
    "sdc_golden_boundary = {}\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "count = 0\n",
    "for index, row in fault_injection_campaign.iterrows():\n",
    "    #print(index)\n",
    "    inject_error = abs(float(row[\"out_xor\"]))\n",
    "    instruction_index = row[\"DI\"]\n",
    "    norm = row[\"diffnormr\"]\n",
    "    \n",
    "    #log scale the inject error\n",
    "    if inject_error > 1:\n",
    "        inject_error = math.log10(inject_error)\n",
    "    \n",
    "    #if inject_error > 20:# and norm < threshold:\n",
    "    #    inject_error = 20\n",
    "    #init\n",
    "    \n",
    "    if instruction_index not in masked_golden_boundary:\n",
    "        #print(instruction_index)\n",
    "        masked_golden_boundary[instruction_index] = 0\n",
    "        sdc_golden_boundary[instruction_index] = 10000#sys.float_info.max\n",
    "        x.append(instruction_index)\n",
    "    \n",
    "    #if the outcome is SDC\n",
    "    if norm > threshold:\n",
    "        if sdc_golden_boundary[instruction_index] > inject_error:\n",
    "            sdc_golden_boundary[instruction_index] = inject_error\n",
    "            count += 1\n",
    "    \n",
    "    #if the outcome is masked\n",
    "    elif norm < threshold:\n",
    "        if masked_golden_boundary[instruction_index] < inject_error:\n",
    "            masked_golden_boundary[instruction_index] = inject_error\n",
    "    \n",
    "# plot the golden boundary\n",
    "for i in x:\n",
    "    y.append(masked_golden_boundary[i])\n",
    "    z.append(sdc_golden_boundary[i])\n",
    "\n",
    "print(threshold)\n",
    "\n",
    "#plt.plot(x, y, color='green')\n",
    "#plt.plot(x, z, color='red')\n",
    "#plt.ylabel(\"Negative Prediction\")\n",
    "#plt.xlabel(\"instruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = -1\n",
    "\n",
    "x1 = np.array(x)[start:end]\n",
    "y1 = np.array(y)[start:end]\n",
    "z1 = np.array(z)[start:end]\n",
    "\n",
    "print(threshold)\n",
    "\n",
    "plt.plot(x1, y1, color='green')\n",
    "#plt.plot(x1, z1, color='red')\n",
    "plt.ylabel(\"boundary value\")\n",
    "plt.xlabel(\"instruction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The standard diviation boxplot.\n",
    "\n",
    "1. Random sample one thousand experiments and draw the standard deviation plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if dataset == \"cg\":\n",
    "    fault_injection_campaign = pd.read_csv('../static/data/cg_in8.csv')\n",
    "    path = \"../static/data/cg/cg_in8\"\n",
    "elif dataset == \"fft\":\n",
    "    fault_injection_campaign = pd.read_csv('../static/data/fft20000.csv')\n",
    "    path = \"../static/data/fft/fft_complete\"\n",
    "elif dataset == \"lu\":\n",
    "    fault_injection_campaign = pd.read_csv('../static/data/lu_complete.csv')\n",
    "    path = \"../static/data/lu/lu_20000\"\n",
    "\n",
    "fault_injection_campaign_sampleset = fault_injection_campaign.sample(n=500, replace=False)\n",
    "masked_runs = []\n",
    "expected_program_length = len(golden_run)\n",
    "golden_run_value = np.array(golden_run['value'], dtype='float')\n",
    "    \n",
    "for index, row in fault_injection_campaign_sampleset.iterrows():\n",
    "    #print(row['oun,tcome'])\n",
    "    #print(row['File_index'])\n",
    "    if row['outcome'] == 'Masked':\n",
    "        fault_inject_run = pd.read_csv(path+\"/appstate_\"+str(row['File_index'])+\".log\",  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "        fault_inject_run_value = np.array(fault_inject_run['value'], dtype='float')\n",
    "        if len(fault_inject_run) < expected_program_length:\n",
    "            continue\n",
    "        masked_runs.append(np.abs(fault_inject_run_value[0:expected_program_length] - golden_run_value))\n",
    "    \n",
    "    \n",
    "masked_runs = np.array(masked_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.mean(masked_runs, axis=0)[0:300], color='green')\n",
    "#plt.plot(np.std(masked_runs, axis=0)[150:350], color='orange')\n",
    "#plt.plot(masked_runs[], color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "golden_run_path = \"../static/data/cg/cg_in8/golden.log\"\n",
    "golden_run = pd.read_csv(golden_run_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'], header=0)\n",
    "golden_run_value = np.array(golden_run.value, dtype='float')\n",
    "cg_fault_injection = pd.read_csv(\"../static/data/cg_in8.csv\")\n",
    "SIZE = len(cg_fault_injection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 -- CG\n",
    "Take all the fault injections in the inital condition. Find all the fault injection cases that result into masked. For each masked case, compare error run with the golden run to get a error run curve. Combine all the error run curve to construct a error boundary for masked and SDC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg_fault_injection_experiment = pd.read_csv('matrix/in10_data/in10/injectlog.log',  sep=' ', names=['file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC Ratio over entire program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iters = list(cg_fault_injection.iter)\n",
    "iters.reverse()\n",
    "count  = 0\n",
    "last_zero_iteration_index = SIZE - iters.index(0)\n",
    "dynamic_step_to_record_computation_result = int(last_zero_iteration_index/64)\n",
    "\n",
    "for i in range(last_zero_iteration_index, len(iters)):\n",
    "    if cg_fault_injection.outcome[i] == \"SDC\":\n",
    "        count += 1\n",
    "\n",
    "print(\"SDC ratio over entire program: \", count/len(iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only tracking the maximum value of the masked run after this time step.\n",
    "tracking_length = len(golden_run_value)\n",
    "\n",
    "def construct_boundary(number_of_dynamic_instruction):\n",
    "    boundary = []\n",
    "    ground_truth = {\"Masked\": 0, \"SDC\":0, \"DUE\":0}\n",
    "\n",
    "    for i in range(tracking_length):\n",
    "        boundary.append({'max':0, 'min':0})\n",
    "\n",
    "    for i in range(number_of_dynamic_instruction):\n",
    "        index = int(random.random() * SIZE)\n",
    "        \n",
    "        ground_truth[cg_fault_injection.outcome[index]] += 1\n",
    "        \n",
    "        if cg_fault_injection.outcome[index] == \"Masked\":\n",
    "            masked_run_path = \"cg_simulation/appstate_\"+ str(index)+\".log\" \n",
    "\n",
    "            #Check whether the tracking file is on the path\n",
    "            #TODO: check whether can regenerate the data\n",
    "            if not os.path.isfile(masked_run_path):\n",
    "                continue\n",
    "\n",
    "            masked_run = pd.read_csv(masked_run_path,  sep=\",\", names=['file', 'linenum', 'variable', 'value'], header=0)\n",
    "            masked_run_value = np.array(masked_run.value, dtype='float')\n",
    "            \n",
    "            #This is a werid information in the data.\n",
    "            #TODO: may check why such outcome is shown\n",
    "            if len(masked_run_value) < tracking_length:\n",
    "                print(\"odd!\")\n",
    "                continue\n",
    "            \n",
    "            #array contain NAN, ignore the run\n",
    "            if np.isnan(np.min(masked_run_value)):\n",
    "                continue\n",
    "            \n",
    "            comparision_result = masked_run_value[0:tracking_length] - golden_run_value\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        for j in range(dynamic_step_to_record_computation_result, tracking_length):\n",
    "            if comparision_result[j] > boundary[j]['max'] and comparision_result[j] >= 0:\n",
    "                boundary[j]['max'] = comparision_result[j]\n",
    "\n",
    "            if comparision_result[j] < boundary[j]['min'] and comparision_result[j] < 0:\n",
    "                boundary[j]['min'] = comparision_result[j]\n",
    "                \n",
    "    return [boundary, ground_truth]\n",
    "\n",
    "def predict(boundary):\n",
    "    masked_true_positive = 0\n",
    "    masked_false_positive = 0\n",
    "    sdc_true_positive = 0\n",
    "    sdc_false_positive = 0\n",
    "    result = {}\n",
    "\n",
    "    for i in range(last_zero_iteration_index + 1, SIZE):\n",
    "        index = math.floor(i/64)\n",
    "        if cg_fault_injection.out_xor[i] < boundary[index]['max'] and cg_fault_injection.out_xor[i] > boundary[index]['min']:\n",
    "            if cg_fault_injection.outcome[i] == \"Masked\":\n",
    "                masked_true_positive += 1\n",
    "            else:\n",
    "                masked_false_positive += 1\n",
    "        else:\n",
    "            if cg_fault_injection.outcome[i] == \"SDC\":\n",
    "                sdc_true_positive += 1\n",
    "            else:\n",
    "                sdc_false_positive += 1\n",
    "\n",
    "    result[\"predict masked case\"] =  (masked_true_positive + masked_false_positive)/SIZE\n",
    "    result[\"predict SDC case\"] = (sdc_true_positive + sdc_false_positive)/SIZE\n",
    "    result[\"masked prediction accuracy\"] = masked_true_positive/(masked_true_positive + masked_false_positive)\n",
    "    result[\"SDC prediction accuracy\"] = sdc_true_positive/(sdc_true_positive + sdc_false_positive)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we think this as a lable propagation problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\n",
    "ground_truth = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    boundary = construct_boundary(2000)    \n",
    "    experiments.append(predict(boundary[0]))\n",
    "    ground_truth.append(boundary[1])\n",
    "\n",
    "    \n",
    "uniform_test = []\n",
    "intuition = []\n",
    "\n",
    "for i in range(10):\n",
    "    intuition.append(experiments[i]['predict SDC case'])\n",
    "    uniform_test.append(ground_truth[i]['SDC']/2000)\n",
    "\n",
    "print(np.mean(intuition))\n",
    "print(intuition)\n",
    "print(np.mean(uniform_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Experiment 2 -- FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"../static/data/cg/cg_in8/\"\n",
    "golden_run_path = path+\"golden.log\"\n",
    "golden_run = pd.read_csv(golden_run_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "golden_run_value = np.array(golden_run.value, dtype='float')\n",
    "fault_injection_experiment = pd.read_csv(path+'injectlog.log',  sep=' ', names=['file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])\n",
    "SIZE = len(fault_injection_experiment)\n",
    "threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    golden_run_path = path + \"golden.log\"\n",
    "    golden_run = pd.read_csv(golden_run_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "    golden_run_value = np.array(golden_run.value, dtype='float')\n",
    "    fault_injection_experiment = pd.read_csv(path+\"injectlog.log\",  sep=' ', names=['file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])\n",
    "    \n",
    "    return [golden_run,fault_injection_experiment]\n",
    "\n",
    "def SDC_ratio(experiments): \n",
    "    sdc_count = 0\n",
    "    for i in range(0, len(experiments)):\n",
    "        if float(experiments.diffnorm[i]) > threshold:\n",
    "            sdc_count += 1\n",
    "    \n",
    "    return sdc_count / len(experiments)\n",
    "\n",
    "def getBoundary(golden_run, percent, experiments, path):\n",
    "    boundary = []\n",
    "    nums = int(len(experiments) * percent)\n",
    "    \n",
    "    print(nums)\n",
    "\n",
    "    for i in range(len(golden_run)):\n",
    "        boundary.append({\"min\": 0, \"max\":0})\n",
    "\n",
    "    for i in range(nums):\n",
    "        \n",
    "        diffnorm = float(experiments.diffnorm[i])\n",
    "        if diffnorm > threshold or math.isnan(diffnorm) or math.isinf(diffnorm):\n",
    "            continue\n",
    "        \n",
    "        index = int(random.random() * len(experiments))\n",
    "\n",
    "        file_path = path+\"appstate_\"+str(index)+\".log\"\n",
    "    \n",
    "        fault_inject_run = pd.read_csv(file_path,  sep=' ', names=[\"file\", \"linenum\", \"variable\", \"value\"])\n",
    "    \n",
    "        if len(fault_inject_run) < len(golden_run):\n",
    "            print(\"weird!\")\n",
    "            continue\n",
    "    \n",
    "        values = np.array(fault_inject_run.value[0:len(golden_run)], dtype=\"float\") - np.array(golden_run.value, dtype=\"float\")\n",
    "    \n",
    "        for j in range(len(golden_run)):              \n",
    "            \n",
    "            if values[j] >= 0 and values[j] > boundary[j][\"max\"]:\n",
    "                boundary[j][\"max\"] = values[j]\n",
    "                       \n",
    "            if values[j] < 0 and values[j] < boundary[j][\"min\"]:\n",
    "                boundary[j][\"min\"] = values[j] \n",
    "    \n",
    "    return boundary\n",
    "\n",
    "def prediction(experiments, boundary, threshold=0.001):\n",
    "    positive_prediction = 0\n",
    "    negative_prediction = 0\n",
    "    crash = 0\n",
    "    length = len(experiments)\n",
    "    \n",
    "    for i in experiments.fileindex:\n",
    "        index = math.floor(i/64)\n",
    "        \n",
    "        #print(i)\n",
    "        \n",
    "        inject_error = float(experiments.corrupt_value[i]) - float(experiments.init_value[i])\n",
    "    \n",
    "        if(inject_error > boundary[index][\"min\"] and inject_error < boundary[index][\"max\"]):\n",
    "            if float(experiments.diffnorm[i]) < threshold:\n",
    "                positive_prediction += 1\n",
    "            elif math.isnan(float(experiments.diffnorm[i])) or math.isinf(float(experiments.diffnorm[i])):\n",
    "                crash += 1\n",
    "            else:\n",
    "                negative_prediction += 1\n",
    "    return {\"positive\": positive_prediction/len(experiments), \"negative\": negative_prediction/len(experiments), \"Crash\": crash/len(experiments)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Result of 20 x 20 Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#golden_run, experiments = load_data(path)\n",
    "#boundary = getBoundary(golden_run, 0.0001, experiments, path)\n",
    "#experiments = pd.read_csv(\"../static/data/cg/cg_in8/injectlog.log\",  sep=' ', names=['file', 'linenum', 'variable','byte_num', 'corrupted','init_value','to', 'corrupt_value', 'mask', 'byte','expo', 'ss', 'op', 'diffnorm', 'empty'])\n",
    "#print(len(experiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using 6400 fault injections run in FFT to test the masked case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary = []\n",
    "\n",
    "for i in range(len(golden_run)):\n",
    "    boundary.append({\"min\": 0, \"max\":0})\n",
    "\n",
    "for i in range(8400):\n",
    "    \n",
    "    if fault_injection_experiment.diffnorm[i] > 0.07:\n",
    "        continue\n",
    "    \n",
    "    index = int(random.random() * len(fault_injection_experiment))\n",
    "\n",
    "    file_path = \"matrix/in27_data/in27/appstate_\"+str(index)+\".log\"\n",
    "    \n",
    "    fault_inject_run = pd.read_csv(file_path,  sep=' ', names=[\"file\", \"linenum\", \"variable\", \"value\"])\n",
    "    \n",
    "    if len(fault_inject_run) < len(golden_run):\n",
    "        print(\"weird!\")\n",
    "        continue\n",
    "    \n",
    "    values = np.array(fault_inject_run.value[0:len(golden_run)], dtype=\"float\") - np.array(golden_run.value, dtype=\"float\")\n",
    "    \n",
    "    for j in range(len(golden_run)):\n",
    "        if values[j] >= 0 and values[j] > boundary[j][\"max\"]:\n",
    "            boundary[j][\"max\"] = values[j]\n",
    "                       \n",
    "        if values[j] < 0 and values[j] < boundary[j][\"min\"]:\n",
    "            boundary[j][\"min\"] = values[j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_prediction = 0\n",
    "negative_prediction = 0\n",
    "for i in range(len(fault_injection_experiment.diffnorm)):\n",
    "    \n",
    "    index = math.floor(i/64)\n",
    "    \n",
    "    #if i%64 <= 52:\n",
    "    #    continue\n",
    "    \n",
    "    inject_error = float(fault_injection_experiment.corrupt_value[i]) - float(fault_injection_experiment.init_value[i])\n",
    "    \n",
    "    if(inject_error > boundary[index][\"min\"] and inject_error < boundary[index][\"max\"]):\n",
    "        if fault_injection_experiment.diffnorm[i] < 0.07:\n",
    "            positive_prediction += 1\n",
    "        else:\n",
    "            negative_prediction += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#relative error and absolute error\n",
    "#for i in range(len(golden_run_value)):\n",
    "#   if golden_run_value[i] != 0:\n",
    "#        absolute = abs(golden_run_value[i] -  masked_run_value[i])\n",
    "\n",
    "false_positive = 0\n",
    "true_positive = 0\n",
    "unsure = 0\n",
    "total = (811 - 160) * 64\n",
    "for i in range(160, 811):\n",
    "    diff = abs(golden_run_value[i] -  masked_run_value[i]) \n",
    "    for b in range(64):\n",
    "        if diff > abs(cg_fault_injection.out_xor[i * 64 + b]) and cg_fault_injection.outcome[i * 64 + b] != \"Masked\":\n",
    "            #print(cg_fault_injection.diffnormr[i * 64 + b], cg_fault_injection.Variable[i * 64 + b], (diff - abs(cg_fault_injection.out_xor[i * 64 + b])))\n",
    "            false_positive += 1\n",
    "            print(i * 64 + b)\n",
    "        elif diff > abs(cg_fault_injection.out_xor[i * 64 + b]) and cg_fault_injection.outcome[i * 64 + b] == \"Masked\":\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            unsure += 1\n",
    "    \n",
    "    #sdc_diff = abs(golden_run_value[i] -  sdc_run_value[i])\n",
    "    #for b in range(64):\n",
    "    #    if sdc_diff < abs(cg_fault_injection.out_xor[i * 64 + b]) and cg_fault_injection.outcome[i * 64 + b] != \"SDC\":\n",
    "    #        false_positive += 1\n",
    "    #    elif sdc_diff < abs(cg_fault_injection.out_xor[i * 64 + b]) and cg_fault_injection.outcome[i * 64 + b] == \"SDC\":\n",
    "    #        true_positive += 1\n",
    "    #    else:\n",
    "    #        unsure +=1\n",
    "            \n",
    "print(false_positive/total)\n",
    "print(true_positive/total)\n",
    "print(unsure/total)\n",
    "    \n",
    "#print(i, cg_fault_injection.Variable[i], cg_fault_injection.out_xor[i], cg_fault_injection.outcome[i])\n",
    "#for i in range(243*64,244*64):\n",
    "#    print(i,cg_fault_injection.Variable[i], cg_fault_injection.out_xor[i], cg_fault_injection.outcome[i])\n",
    "#print(golden_run_value[243])\n",
    "#print(len(cg_fault_injection))\n",
    "#golden_run_value-error_run_value[0:811]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_instructions = {}\n",
    "\n",
    "propagation_path = []\n",
    "\n",
    "for index in range(100):\n",
    "    if index in[15731, 16246, 17523]:\n",
    "        continue\n",
    "    \n",
    "    file_path = \"cg_simulation/appstate_\"+str(index)+\".log\"\n",
    "    error_run = pd.read_csv(file_path,  sep=' ')\n",
    "    \n",
    "    \n",
    "    #For different fault injection case, what is the number of different execution dynamic instructions\n",
    "    if len(error_run) in number_of_instructions:\n",
    "        number_of_instructions[len(error_run)] += 1\n",
    "    else:\n",
    "        number_of_instructions[len(error_run)] = 1\n",
    "        \n",
    "    #\n",
    "    index = min(len(golden_run), len(error_run))\n",
    "    #result = np.array(golden_run.value, dtype=float)[:index] - np.array(error_run.value, dtype=float)[:index]\n",
    "    #propagation_elements = golden_run.line[np.where(result != 0)[0]]\n",
    "    \n",
    "    #path = \"=>\"\n",
    "    #number_of_propagation_element = 5\n",
    "    #for e in propagation_elements:\n",
    "    #    if str(e) not in path:\n",
    "    #        path += str(e)\n",
    "    #        path += \"=>\"\n",
    "    #        number_of_propagation_element -= 1\n",
    "        \n",
    "    #    if number_of_propagation_element == 0:\n",
    "    #        break\n",
    "    #if path not in propagation_path:\n",
    "    #    propagation_path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the probability of the different number of storing dynamic instructions.\n",
    "## What is the probability of SDC.\n",
    "\n",
    "It's expected that if the program ends early, then there an unexpected crash during the program execution in the earlier stage. At the same time, if the program has more execution than it expected. It will have high chance causes silent data corruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg_outcome = cg_fault_injection['outcome'].value_counts()\n",
    "\n",
    "print(cg_outcome)\n",
    "print(sum(cg_outcome))\n",
    "#propagation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# If you want to rewrite your code.\n",
    "\n",
    "4. interactive fault injection campaign.\n",
    "\n",
    "### 1. A sensitive analysis across the whole program with a mapping framework.\n",
    "A desity scatter plot to understand the input and output sensitivity of the program. User can selective choose the high sensitive data and mapping back to the original visualization.\n",
    "    \n",
    "    a. how many clusters in the plot.\n",
    "    \n",
    "    b. Where is each of them comes from. \n",
    "    \n",
    "    c. The sample that comes from the fault injection in same location.\n",
    "\n",
    "#### 2. Explore function level resiliency of the program. What's the difference compare to the source code level?\n",
    "\n",
    "    a.Explore the resiliency of different program component. Aggregate the data in variable level\n",
    "\n",
    "\n",
    "#### 3. How to measure the impact of one variable/function over the other?\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The number of times a function is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = {}\n",
    "\n",
    "line_to_func = {167:'readA', 175:'readB', 33:'waxpby', 25:'matvec', 48:'dot_r2', 75:'solve_cg', 76:'solve_cg',87:'solve_cg',57:'dot', 90:'solve_cg',91:'solve_cg',40:\"daxpby\", 82:'daxpby',83:'daxpby',84:'daxpby'}\n",
    "\n",
    "for index, row in golden_run.iterrows():\n",
    "    key = line_to_func[row['line']]\n",
    "    if key not in counter:\n",
    "        counter[key] = 1\n",
    "    else:\n",
    "        counter[key] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_instruction = sum(list(counter.values()))\n",
    "for item in counter.items():\n",
    "    print(item[0], item[1]/number_of_instruction * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Error Propagation Analysis in one program component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "golden_run_path = \"cg_simulation/golden.log\"\n",
    "golden_run = pd.read_csv(golden_run_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "golden_run_value = np.array(golden_run.value)\n",
    "##### this is a very interesting but werid case\n",
    "##### There is a NAN occur during the computation, but the  error is masked at the end.\n",
    "#index_range = [17341, 24381]\n",
    "\n",
    "##### cg p_ap_dot first interation 64 experiment\n",
    "#index_range = [15552, 15603]\n",
    "\n",
    "#file_path = \"cg_simulation1/appstate_\"+str(17341)+\".log\"\n",
    "#error_run = pd.read_csv(file_path,  sep=' ')\n",
    "\n",
    "#for i in range(len(error_run.value)):\n",
    "#    print(error_run.line[i], error_run.variable[i], error_run.value[i])\n",
    "#print(len(error_run.value))\n",
    "\n",
    "#print(error_run)\n",
    "#data_set = {}\n",
    "\n",
    "\n",
    "#golden_run_value = np.array(golden_run.value[0:800], dtype='float')\n",
    "\n",
    "#for index in range(index_range[0], index_range[1]+1):\n",
    "#    file_path = \"cg_simulation/appstate_\"+str(index)+\".log\"\n",
    "#    error_run = pd.read_csv(file_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "\n",
    "#    data_set[index] = golden_run_value - np.array(error_run.value[0:800], dtype='float')\n",
    "\n",
    "\n",
    "##### a specific case line 75 case 10290\n",
    "##### a specific case line 75 case 10296\n",
    "indexs =  [10290, 10274]# 10288] #10297]# 10296, 10289]\n",
    "\n",
    "delta_x = [65536, 1.0]# 1321922331132047.5]#, -307779.3308780107]\n",
    "x_data = range(0, 811, 1)\n",
    "\n",
    "for index,item in enumerate(indexs): \n",
    "    file_path = \"cg_simulation/appstate_\"+str(item)+\".log\"\n",
    "    error_run = pd.read_csv(file_path,  sep=' ', names=['file', 'linenum', 'variable', 'value'])\n",
    "    error_run_value = np.array(error_run.value)\n",
    "\n",
    "    sensitivity_val = (error_run_value[0:811] - golden_run_value[0:811])/delta_x[index]\n",
    "    sns.lineplot(x=x_data, y=sensitivity_val, sort=False, lw=1)\n",
    "    \n",
    "print(sensitivity_val.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for index in range(index_range[0], index_range[1]+1):\n",
    "#    print(len(data_set[index].values))\n",
    "#data_set[index] = golden_run.values - error_run.values   \n",
    "\n",
    "\n",
    "x_data = range(0,811,1)\n",
    "sns.lineplot(x=x_data, y=sensitivity_val, sort=False, lw=1)\n",
    "\n",
    "#for index in range(index_range[0], index_range[0]+20): \n",
    "#    sns.lineplot(x=x_data, y=data_set[index], sort=False, lw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What role the truncation error is playing in the propagation analysis\n",
    "## What's the threshold of different program components.\n",
    "## How much error is masked by the truncate error and How much error is masked by the model feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
